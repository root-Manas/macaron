#!/usr/bin/env python3
"""
MACARON v2.1 - Massive Automated Comprehensive Asset Reconnaissance & Offensive Nexus
A configurable security reconnaissance CLI with YAML-based pipeline configuration
"""
import argparse
import sys
import json
import os
import shutil
import subprocess
import tempfile
import signal
import re
import time
import threading
from pathlib import Path
from datetime import datetime, timezone
from typing import List, Dict, Any, Optional, Set, Tuple
from dataclasses import dataclass, field
from enum import Enum
from concurrent.futures import ThreadPoolExecutor, as_completed
import logging

# YAML support
try:
    import yaml
    YAML_AVAILABLE = True
except ImportError:
    YAML_AVAILABLE = False

# Rich for beautiful CLI UI
try:
    from rich.console import Console
    from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn, TaskProgressColumn, TimeElapsedColumn, TimeRemainingColumn
    from rich.panel import Panel
    from rich.table import Table
    from rich.live import Live
    from rich.layout import Layout
    from rich.text import Text
    from rich.style import Style
    from rich import box
    from rich.tree import Tree
    from rich.syntax import Syntax
    RICH_AVAILABLE = True
except ImportError:
    RICH_AVAILABLE = False
    print("[!] Rich library not found. Install with: pip install rich")

# ============== CONSTANTS ==============

VERSION = "2.4.0"
BANNER = """[bold cyan]
‚ñà‚ñà‚ñà‚ïó   ‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ïó   ‚ñà‚ñà‚ïó
‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ïë
‚ñà‚ñà‚ïî‚ñà‚ñà‚ñà‚ñà‚ïî‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ñà‚ñà‚ïó ‚ñà‚ñà‚ïë
‚ñà‚ñà‚ïë‚ïö‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë     ‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë‚ïö‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë
‚ñà‚ñà‚ïë ‚ïö‚ïê‚ïù ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë‚ïö‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë‚ïö‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ïë ‚ïö‚ñà‚ñà‚ñà‚ñà‚ïë
‚ïö‚ïê‚ïù     ‚ïö‚ïê‚ïù‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïù ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïù‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïù ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù ‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïê‚ïê‚ïù[/]
[dim]        v{version} | github.com/root-Manas/macaron[/]
"""

# Directories
HOME_DIR = Path.home() / ".macaron"
DATA_DIR = HOME_DIR / "data"
CONFIG_DIR = HOME_DIR / "config"
STATE_DIR = HOME_DIR / "state"
LOGS_DIR = HOME_DIR / "logs"
WORDLISTS_DIR = HOME_DIR / "wordlists"
PIPELINE_FILE = CONFIG_DIR / "pipeline.yaml"
CONFIG_FILE = CONFIG_DIR / "config.yaml"

# Bundled config paths (in repo)
BUNDLED_PIPELINE = Path(__file__).parent / "config" / "pipeline.yaml"
BUNDLED_CONFIG = Path(__file__).parent / "config" / "config.yaml"

# Console for Rich output (force terminal to avoid issues in non-TTY)
try:
    console = Console(force_terminal=True, stderr=True) if RICH_AVAILABLE else None
except Exception:
    console = None

# ============== PIPELINE CONFIG ==============

def get_default_pipeline_config() -> Dict:
    """Return default embedded pipeline config"""
    return {
        "global": {
            "rate_limit": 100,
            "threads": 25,
            "use_proxy": True,
            "slow_mode": {"rate_limit": 10, "threads": 5}
        },
        "tools": {
            "subfinder": {"cmd": "subfinder -d {target} -silent -all -t {threads}", "timeout": 600, "input": "target", "output": "stdout_lines", "installed_check": "subfinder"},
            "amass": {"cmd": "amass enum -passive -d {target} -dns-qps 50 -timeout 10", "timeout": 600, "input": "target", "output": "stdout_lines", "installed_check": "amass"},
            "assetfinder": {"cmd": "assetfinder --subs-only {target}", "timeout": 300, "input": "target", "output": "stdout_lines", "installed_check": "assetfinder"},
            "findomain": {"cmd": "findomain -t {target} -q", "timeout": 300, "input": "target", "output": "stdout_lines", "installed_check": "findomain"},
            "crtsh": {"cmd": "curl -s 'https://crt.sh/?q=%25.{target}&output=json' | jq -r '.[].name_value' | sort -u", "timeout": 60, "input": "target", "output": "stdout_lines", "installed_check": "curl"},
            "dnsx": {"cmd": "dnsx -l {input_file} -a -resp -json -silent -t {threads}", "timeout": 600, "input": "file", "output": "json_lines", "installed_check": "dnsx", "parser": "dnsx"},
            "naabu": {"cmd": "naabu -l {input_file} -json -silent -top-ports 1000 -rate {rate} -c {threads} -retries 2", "timeout": 1800, "input": "file", "output": "json_lines", "installed_check": "naabu", "parser": "naabu"},
            "naabu_quick": {"cmd": "naabu -l {input_file} -json -silent -p 80,443,8080,8443,8000,3000,5000,9000 -rate {rate}", "timeout": 300, "input": "file", "output": "json_lines", "installed_check": "naabu", "parser": "naabu"},
            "httpx": {"cmd": "httpx -l {input_file} -json -silent -sc -title -td -cdn -follow-redirects -rate-limit {rate} -threads {threads}", "timeout": 1800, "input": "file", "output": "json_lines", "installed_check": "httpx", "parser": "httpx"},
            "gau": {"cmd": "gau --subs --threads 5 {target}", "timeout": 300, "input": "target", "output": "stdout_lines", "installed_check": "gau"},
            "waybackurls": {"cmd": "echo {target} | waybackurls", "timeout": 300, "input": "target", "output": "stdout_lines", "installed_check": "waybackurls"},
            "katana": {"cmd": "katana -list {input_file} -silent -d 3 -jc -iqp -c {threads} -rl {rate}", "timeout": 900, "input": "file", "output": "stdout_lines", "installed_check": "katana"},
            "katana_deep": {"cmd": "katana -list {input_file} -silent -d 5 -jc -iqp -c {threads} -rl {rate}", "timeout": 1200, "input": "file", "output": "stdout_lines", "installed_check": "katana"},
            "hakrawler": {"cmd": "echo {target} | hakrawler -d 2 -subs -u", "timeout": 300, "input": "target", "output": "stdout_lines", "installed_check": "hakrawler"},
            "getjs": {"cmd": "getJS --url {target} --complete", "timeout": 120, "input": "target", "output": "stdout_lines", "installed_check": "getJS"},
            "ffuf": {"cmd": "ffuf -u {target}/FUZZ -w {wordlist} -o {output_file} -of json -mc 200,201,204,301,302,307,401,403,405 -t {threads} -rate {rate} -s", "timeout": 600, "input": "target", "output": "file", "installed_check": "ffuf", "options": {"wordlist": "~/.macaron/wordlists/common.txt"}},
            "gowitness": {"cmd": "gowitness scan file -f {input_file} --screenshot-path {output_dir} --delay 2 --threads {threads}", "timeout": 3600, "input": "file", "output": "directory", "installed_check": "gowitness"},
            "nuclei": {"cmd": "nuclei -l {input_file} -o {output_file} -jsonl -silent -severity {severity} -rl {rate} -c {threads} -nh", "timeout": 7200, "input": "file", "output": "json_lines", "installed_check": "nuclei", "options": {"severity": "critical,high,medium"}},
            "nuclei_fast": {"cmd": "nuclei -l {input_file} -o {output_file} -jsonl -silent -severity critical,high -rl {rate} -c {threads} -nh", "timeout": 3600, "input": "file", "output": "json_lines", "installed_check": "nuclei"},
        },
        "pipelines": {
            "wide": {
                "description": "Full infrastructure reconnaissance",
                "stages": [
                    {"name": "Subdomain Discovery", "emoji": "üîç", "tools": ["subfinder", "assetfinder", "findomain", "crtsh", "amass"], "input_from": "target", "output_to": "subdomains", "enabled": True},
                    {"name": "DNS Resolution", "emoji": "üì°", "tools": ["dnsx"], "input_from": "subdomains", "output_to": "resolved", "enabled": True},
                    {"name": "Port Scanning", "emoji": "üîå", "tools": ["naabu"], "input_from": "resolved", "output_to": "ports", "enabled": True},
                    {"name": "HTTP Probing", "emoji": "üåê", "tools": ["httpx"], "input_from": "subdomains+ports", "output_to": "live_hosts", "enabled": True},
                    {"name": "URL Discovery", "emoji": "üîó", "tools": ["gau", "waybackurls", "katana"], "input_from": "live_hosts", "output_to": "urls", "enabled": True},
                    {"name": "JS Analysis", "emoji": "üìú", "tools": ["getjs"], "input_from": "live_hosts", "output_to": "js_files", "limit": 20, "enabled": True},
                    {"name": "Screenshots", "emoji": "üì∏", "tools": ["gowitness"], "input_from": "live_hosts", "output_to": "screenshots", "limit": 50, "enabled": True},
                    {"name": "Vulnerability Scan", "emoji": "üéØ", "tools": ["nuclei"], "input_from": "live_hosts", "output_to": "vulnerabilities", "enabled": True},
                ]
            },
            "narrow": {
                "description": "Application-focused testing",
                "stages": [
                    {"name": "DNS Validation", "emoji": "üì°", "tools": ["dnsx"], "input_from": "target", "output_to": "resolved", "enabled": True},
                    {"name": "Port Scan", "emoji": "üîå", "tools": ["naabu_quick"], "input_from": "target", "output_to": "ports", "enabled": True},
                    {"name": "HTTP Probing", "emoji": "üåê", "tools": ["httpx"], "input_from": "target", "output_to": "live_hosts", "enabled": True},
                    {"name": "Deep Crawling", "emoji": "üï∑Ô∏è", "tools": ["katana_deep", "hakrawler"], "input_from": "live_hosts", "output_to": "urls", "enabled": True},
                    {"name": "URL Archives", "emoji": "üîó", "tools": ["gau", "waybackurls"], "input_from": "target", "output_to": "urls", "enabled": True},
                    {"name": "JS Analysis", "emoji": "üìú", "tools": ["getjs"], "input_from": "live_hosts", "output_to": "js_files", "enabled": True},
                    {"name": "Content Discovery", "emoji": "üìÇ", "tools": ["ffuf"], "input_from": "live_hosts", "output_to": "content", "limit": 3, "enabled": True},
                    {"name": "Screenshots", "emoji": "üì∏", "tools": ["gowitness"], "input_from": "live_hosts", "output_to": "screenshots", "enabled": True},
                    {"name": "Vulnerability Scan", "emoji": "üéØ", "tools": ["nuclei"], "input_from": "live_hosts", "output_to": "vulnerabilities", "enabled": True},
                ]
            },
            "fast": {
                "description": "Quick scan for immediate wins",
                "stages": [
                    {"name": "Quick Subdomains", "emoji": "üîç", "tools": ["subfinder", "crtsh"], "input_from": "target", "output_to": "subdomains", "enabled": True},
                    {"name": "HTTP Probing", "emoji": "üåê", "tools": ["httpx"], "input_from": "subdomains", "output_to": "live_hosts", "limit": 100, "enabled": True},
                    {"name": "Quick Vuln Scan", "emoji": "üéØ", "tools": ["nuclei_fast"], "input_from": "live_hosts", "output_to": "vulnerabilities", "limit": 50, "enabled": True},
                ]
            }
        },
        "parsers": {
            "dnsx": {"host_field": "host", "data_field": "a"},
            "naabu": {"host_field": "host", "port_field": "port"},
            "httpx": {"url_field": "url", "tech_field": "tech", "status_field": "status_code", "title_field": "title"},
        },
        "discord": {"enabled": False, "webhook_url": "", "notify_on": ["scan_start", "scan_complete", "vulnerability_found"], "vuln_severity": ["critical", "high"]}
    }

def load_pipeline_config() -> Dict:
    """Load pipeline config from YAML file or use defaults"""
    config = get_default_pipeline_config()
    
    # Try loading from user config
    if PIPELINE_FILE.exists() and YAML_AVAILABLE:
        try:
            with open(PIPELINE_FILE) as f:
                user_config = yaml.safe_load(f)
                if user_config:
                    # Deep merge user config with defaults
                    config = deep_merge(config, user_config)
        except Exception as e:
            if console:
                console.print(f"[yellow]Warning: Could not load pipeline.yaml: {e}[/]")
    
    # Try bundled config
    elif BUNDLED_PIPELINE.exists() and YAML_AVAILABLE:
        try:
            with open(BUNDLED_PIPELINE) as f:
                bundled = yaml.safe_load(f)
                if bundled:
                    config = deep_merge(config, bundled)
        except:
            pass
    
    return config

def deep_merge(base: Dict, override: Dict) -> Dict:
    """Deep merge two dictionaries"""
    result = base.copy()
    for key, value in override.items():
        if key in result and isinstance(result[key], dict) and isinstance(value, dict):
            result[key] = deep_merge(result[key], value)
        else:
            result[key] = value
    return result

def save_pipeline_config(config: Dict):
    """Save pipeline config to YAML"""
    ensure_dir(CONFIG_DIR)
    if YAML_AVAILABLE:
        with open(PIPELINE_FILE, 'w') as f:
            yaml.dump(config, f, default_flow_style=False, sort_keys=False, allow_unicode=True)

# ============== ENUMS ==============

class Mode(Enum):
    WIDE = "wide"
    NARROW = "narrow"
    FAST = "fast"  # New: Quick scan with minimal tools

class Status(Enum):
    PENDING = "pending"
    RUNNING = "running"
    DONE = "done"
    FAILED = "failed"
    SKIPPED = "skipped"

# ============== THEME / COLORS ==============

class Theme:
    """Color theme for the UI"""
    PRIMARY = "cyan"
    SECONDARY = "blue"
    SUCCESS = "green"
    WARNING = "yellow"
    ERROR = "red"
    INFO = "white"
    DIM = "dim"
    HIGHLIGHT = "bold magenta"
    
    # Stage colors
    STAGE_SUBDOMAIN = "bold cyan"
    STAGE_DNS = "bold blue"
    STAGE_PORT = "bold yellow"
    STAGE_HTTP = "bold green"
    STAGE_URL = "bold magenta"
    STAGE_JS = "bold cyan"
    STAGE_SCREEN = "bold blue"
    STAGE_VULN = "bold red"

# ============== UTILITIES ==============

def ensure_dir(path: Path) -> Path:
    path.mkdir(parents=True, exist_ok=True)
    return path

def is_installed(tool: str) -> bool:
    return shutil.which(tool) is not None

def sanitize(target: str) -> str:
    return re.sub(r'[^\w\-.]', '_', target.replace("https://", "").replace("http://", "").split("/")[0])

def strip_protocol(url: str) -> str:
    return url.replace("https://", "").replace("http://", "").split("/")[0].split(":")[0]

def save_list(filepath: Path, items):
    with open(filepath, 'w') as f:
        for item in sorted(set(items)):
            f.write(f"{item}\n")

def load_list(filepath: Path) -> List[str]:
    if filepath.exists():
        with open(filepath) as f:
            return [l.strip() for l in f if l.strip()]
    return []

def get_default_config() -> Dict:
    """Return default main configuration"""
    return {
        "general": {
            "max_concurrent_scans": 3,
            "default_threads": 25,
            "default_rate_limit": 100
        },
        "discord": {
            "enabled": False,
            "webhook_url": "",
            "notify_on": ["scan_start", "scan_complete", "new_subdomain", "new_vulnerability"],
            "rate_limit_seconds": 5
        },
        "proxy": {
            "enabled": True,
            "use_proxychains": True
        },
        "rate_limits": {
            "global_requests_per_second": 100,
            "per_domain_requests_per_second": 10,
            "slow_mode_rate": 10,
            "slow_mode_threads": 5
        },
        "filtering": {
            "exclude_patterns": [],
            "include_only_in_scope": True,
            "auto_detect_wildcards": True,
            "remove_duplicates": True
        },
        "api_keys": {
            "shodan": "",
            "censys_id": "",
            "censys_secret": "",
            "virustotal": "",
            "securitytrails": "",
            "chaos": "",
            "github": ""
        }
    }

def load_config() -> Dict:
    """Load main config from YAML file or use defaults"""
    config = get_default_config()
    
    # Try loading from user config.yaml
    if CONFIG_FILE.exists() and YAML_AVAILABLE:
        try:
            with open(CONFIG_FILE) as f:
                user_config = yaml.safe_load(f)
                if user_config:
                    config = deep_merge(config, user_config)
        except Exception as e:
            if console:
                console.print(f"[yellow]Warning: Could not load config.yaml: {e}[/]")
    # Try bundled config
    elif BUNDLED_CONFIG.exists() and YAML_AVAILABLE:
        try:
            with open(BUNDLED_CONFIG) as f:
                bundled = yaml.safe_load(f)
                if bundled:
                    config = deep_merge(config, bundled)
        except (yaml.YAMLError, IOError):
            pass
    
    return config

def save_config(config: Dict):
    """Save main config to YAML"""
    ensure_dir(CONFIG_DIR)
    if YAML_AVAILABLE:
        with open(CONFIG_FILE, 'w') as f:
            yaml.dump(config, f, default_flow_style=False, sort_keys=False, allow_unicode=True)

def get_timestamp() -> str:
    return datetime.now(timezone.utc).isoformat().replace('+00:00', 'Z')

# ============== DIFF TRACKER ==============

class DiffTracker:
    """Track new assets discovered since last scan"""
    
    def __init__(self, target_dir: Path):
        self.target_dir = target_dir
        self.history_file = target_dir / ".scan_history.json"
        self.previous = self._load_previous()
        self.current = {
            "subdomains": set(),
            "live_hosts": set(),
            "urls": set(),
            "ports": set(),
            "vulnerabilities": []
        }
        self.new_assets = {
            "subdomains": set(),
            "live_hosts": set(),
            "urls": set(),
            "ports": set(),
            "vulnerabilities": []
        }
    
    def _load_previous(self) -> Dict:
        """Load previous scan data"""
        if self.history_file.exists():
            try:
                with open(self.history_file) as f:
                    data = json.load(f)
                    return {
                        "subdomains": set(data.get("subdomains", [])),
                        "live_hosts": set(data.get("live_hosts", [])),
                        "urls": set(data.get("urls", [])),
                        "ports": set(data.get("ports", [])),
                        "vulnerabilities": data.get("vulnerabilities", []),
                        "last_scan": data.get("last_scan", "")
                    }
            except (json.JSONDecodeError, IOError):
                pass
        return {"subdomains": set(), "live_hosts": set(), "urls": set(), "ports": set(), "vulnerabilities": [], "last_scan": ""}
    
    def update(self, asset_type: str, items):
        """Track current scan assets"""
        if asset_type == "vulnerabilities":
            if isinstance(items, list):
                self.current["vulnerabilities"].extend(items)
        elif isinstance(items, (set, list)):
            self.current[asset_type].update(items)
    
    def compute_diff(self) -> Dict:
        """Compute new assets since last scan"""
        for key in ["subdomains", "live_hosts", "urls", "ports"]:
            self.new_assets[key] = self.current[key] - self.previous.get(key, set())
        
        # For vulnerabilities, compare by template-id + host
        prev_vuln_keys = {(v.get("template", ""), v.get("host", "")) for v in self.previous.get("vulnerabilities", [])}
        self.new_assets["vulnerabilities"] = [
            v for v in self.current["vulnerabilities"]
            if (v.get("template", ""), v.get("host", "")) not in prev_vuln_keys
        ]
        
        return {
            "new_subdomains": len(self.new_assets["subdomains"]),
            "new_live_hosts": len(self.new_assets["live_hosts"]),
            "new_urls": len(self.new_assets["urls"]),
            "new_ports": len(self.new_assets["ports"]),
            "new_vulnerabilities": len(self.new_assets["vulnerabilities"]),
            "last_scan": self.previous.get("last_scan", "Never")
        }
    
    def save(self):
        """Save current scan as history for next diff"""
        data = {
            "subdomains": list(self.current["subdomains"]),
            "live_hosts": list(self.current["live_hosts"]),
            "urls": list(self.current["urls"]),
            "ports": list(self.current["ports"]),
            "vulnerabilities": self.current["vulnerabilities"],
            "last_scan": get_timestamp()
        }
        with open(self.history_file, 'w') as f:
            json.dump(data, f)
    
    def save_diff_report(self):
        """Save diff report to file"""
        diff = self.compute_diff()
        report_file = self.target_dir / "diff_report.txt"
        with open(report_file, 'w') as f:
            f.write(f"=== DIFF REPORT ===\n")
            f.write(f"Previous scan: {diff['last_scan']}\n")
            f.write(f"Current scan:  {get_timestamp()}\n\n")
            
            if self.new_assets["subdomains"]:
                f.write(f"[+] NEW SUBDOMAINS ({len(self.new_assets['subdomains'])})\n")
                for s in sorted(self.new_assets["subdomains"]):
                    f.write(f"    {s}\n")
            
            if self.new_assets["live_hosts"]:
                f.write(f"\n[+] NEW LIVE HOSTS ({len(self.new_assets['live_hosts'])})\n")
                for h in sorted(self.new_assets["live_hosts"]):
                    f.write(f"    {h}\n")
            
            if self.new_assets["ports"]:
                f.write(f"\n[+] NEW PORTS ({len(self.new_assets['ports'])})\n")
                for p in sorted(self.new_assets["ports"]):
                    f.write(f"    {p}\n")
            
            if self.new_assets["vulnerabilities"]:
                f.write(f"\n[!] NEW VULNERABILITIES ({len(self.new_assets['vulnerabilities'])})\n")
                for v in self.new_assets["vulnerabilities"]:
                    f.write(f"    [{v.get('severity', 'info').upper()}] {v.get('name', '')} @ {v.get('host', '')}\n")

# ============== STATE MANAGER (Resume Support) ==============

class StateManager:
    """Manage scan state for pause/resume capability"""
    
    def __init__(self, target: str):
        self.target = sanitize(target)
        self.state_file = STATE_DIR / f"{self.target}.state.json"
        ensure_dir(STATE_DIR)
    
    def save_state(self, ctx: Dict, current_stage: int, mode: str):
        """Save current scan state"""
        state = {
            "target": ctx["target"],
            "mode": mode,
            "current_stage": current_stage,
            "saved_at": get_timestamp(),
            "subdomains": list(ctx.get("subdomains", set())),
            "resolved": ctx.get("resolved", {}),
            "ports": ctx.get("ports", {}),
            "live_hosts": list(ctx.get("live_hosts", set())),
            "urls": list(ctx.get("urls", set())),
            "js_files": list(ctx.get("js_files", set())),
            "vulnerabilities": ctx.get("vulnerabilities", []),
            "technologies": ctx.get("technologies", {}),
            "errors": ctx.get("errors", [])
        }
        with open(self.state_file, 'w') as f:
            json.dump(state, f, indent=2)
    
    def load_state(self) -> Optional[Dict]:
        """Load saved state if exists"""
        if not self.state_file.exists():
            return None
        try:
            with open(self.state_file) as f:
                state = json.load(f)
            # Convert lists back to sets
            state["subdomains"] = set(state.get("subdomains", []))
            state["live_hosts"] = set(state.get("live_hosts", []))
            state["urls"] = set(state.get("urls", []))
            state["js_files"] = set(state.get("js_files", []))
            return state
        except (json.JSONDecodeError, IOError):
            return None
    
    def has_state(self) -> bool:
        return self.state_file.exists()
    
    def clear_state(self):
        """Remove state file after successful completion"""
        if self.state_file.exists():
            self.state_file.unlink()
    
    def get_resume_info(self) -> Optional[Dict]:
        """Get info about saved state for user prompt"""
        state = self.load_state()
        if state:
            return {
                "mode": state.get("mode", "unknown"),
                "stage": state.get("current_stage", 0),
                "saved_at": state.get("saved_at", "unknown"),
                "subdomains": len(state.get("subdomains", [])),
                "live_hosts": len(state.get("live_hosts", []))
            }
        return None

# ============== SCREENSHOT GALLERY ==============

class ScreenshotGallery:
    """Generate HTML gallery from screenshots"""
    
    HTML_TEMPLATE = '''<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Screenshot Gallery - {target}</title>
    <style>
        * {{ margin: 0; padding: 0; box-sizing: border-box; }}
        body {{
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, sans-serif;
            background: #0d1117;
            color: #c9d1d9;
            padding: 20px;
        }}
        .header {{
            text-align: center;
            padding: 30px 0;
            border-bottom: 1px solid #30363d;
            margin-bottom: 30px;
        }}
        .header h1 {{
            color: #58a6ff;
            font-size: 2em;
            margin-bottom: 10px;
        }}
        .header .meta {{
            color: #8b949e;
            font-size: 0.9em;
        }}
        .stats {{
            display: flex;
            justify-content: center;
            gap: 30px;
            margin: 20px 0;
        }}
        .stat {{
            background: #161b22;
            padding: 15px 25px;
            border-radius: 8px;
            border: 1px solid #30363d;
        }}
        .stat-value {{
            font-size: 1.8em;
            font-weight: bold;
            color: #58a6ff;
        }}
        .stat-label {{
            color: #8b949e;
            font-size: 0.85em;
        }}
        .filters {{
            display: flex;
            justify-content: center;
            gap: 10px;
            margin: 20px 0;
            flex-wrap: wrap;
        }}
        .filter-btn {{
            background: #21262d;
            border: 1px solid #30363d;
            color: #c9d1d9;
            padding: 8px 16px;
            border-radius: 6px;
            cursor: pointer;
            transition: all 0.2s;
        }}
        .filter-btn:hover, .filter-btn.active {{
            background: #58a6ff;
            color: #0d1117;
            border-color: #58a6ff;
        }}
        .search-box {{
            display: flex;
            justify-content: center;
            margin: 20px 0;
        }}
        .search-box input {{
            width: 400px;
            max-width: 90%;
            padding: 12px 16px;
            background: #161b22;
            border: 1px solid #30363d;
            border-radius: 6px;
            color: #c9d1d9;
            font-size: 1em;
        }}
        .search-box input:focus {{
            outline: none;
            border-color: #58a6ff;
        }}
        .gallery {{
            display: grid;
            grid-template-columns: repeat(auto-fill, minmax(400px, 1fr));
            gap: 20px;
            padding: 20px 0;
        }}
        .card {{
            background: #161b22;
            border: 1px solid #30363d;
            border-radius: 8px;
            overflow: hidden;
            transition: transform 0.2s, box-shadow 0.2s;
        }}
        .card:hover {{
            transform: translateY(-4px);
            box-shadow: 0 8px 24px rgba(0,0,0,0.4);
        }}
        .card-img {{
            width: 100%;
            height: 250px;
            object-fit: cover;
            object-position: top;
            cursor: pointer;
            border-bottom: 1px solid #30363d;
        }}
        .card-body {{
            padding: 15px;
        }}
        .card-title {{
            font-size: 0.9em;
            color: #58a6ff;
            word-break: break-all;
            margin-bottom: 8px;
        }}
        .card-title a {{
            color: #58a6ff;
            text-decoration: none;
        }}
        .card-title a:hover {{
            text-decoration: underline;
        }}
        .card-meta {{
            display: flex;
            gap: 10px;
            flex-wrap: wrap;
        }}
        .badge {{
            font-size: 0.75em;
            padding: 3px 8px;
            border-radius: 4px;
            background: #21262d;
            color: #8b949e;
        }}
        .badge.status-2xx {{ background: #238636; color: white; }}
        .badge.status-3xx {{ background: #1f6feb; color: white; }}
        .badge.status-4xx {{ background: #da3633; color: white; }}
        .badge.status-5xx {{ background: #6e40c9; color: white; }}
        .modal {{
            display: none;
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: rgba(0,0,0,0.9);
            z-index: 1000;
            justify-content: center;
            align-items: center;
        }}
        .modal.active {{
            display: flex;
        }}
        .modal img {{
            max-width: 95%;
            max-height: 95%;
            border-radius: 8px;
        }}
        .modal-close {{
            position: fixed;
            top: 20px;
            right: 30px;
            font-size: 2em;
            color: white;
            cursor: pointer;
        }}
        .no-results {{
            text-align: center;
            padding: 60px;
            color: #8b949e;
        }}
        @media (max-width: 600px) {{
            .gallery {{
                grid-template-columns: 1fr;
            }}
        }}
    </style>
</head>
<body>
    <div class="header">
        <h1>üñºÔ∏è Screenshot Gallery</h1>
        <div class="meta">Target: <strong>{target}</strong> | Generated: {timestamp}</div>
    </div>
    
    <div class="stats">
        <div class="stat">
            <div class="stat-value">{total_screenshots}</div>
            <div class="stat-label">Screenshots</div>
        </div>
        <div class="stat">
            <div class="stat-value">{unique_hosts}</div>
            <div class="stat-label">Unique Hosts</div>
        </div>
    </div>
    
    <div class="search-box">
        <input type="text" id="search" placeholder="Search URLs..." onkeyup="filterCards()">
    </div>
    
    <div class="filters">
        <button class="filter-btn active" onclick="filterByStatus('all')">All</button>
        <button class="filter-btn" onclick="filterByStatus('2xx')">2xx</button>
        <button class="filter-btn" onclick="filterByStatus('3xx')">3xx</button>
        <button class="filter-btn" onclick="filterByStatus('4xx')">4xx</button>
        <button class="filter-btn" onclick="filterByStatus('5xx')">5xx</button>
    </div>
    
    <div class="gallery" id="gallery">
        {cards}
    </div>
    
    <div class="no-results" id="no-results" style="display:none;">
        No screenshots match your search.
    </div>
    
    <div class="modal" id="modal" onclick="closeModal()">
        <span class="modal-close">&times;</span>
        <img id="modal-img" src="" alt="">
    </div>
    
    <script>
        function openModal(src) {{
            document.getElementById('modal-img').src = src;
            document.getElementById('modal').classList.add('active');
        }}
        
        function closeModal() {{
            document.getElementById('modal').classList.remove('active');
        }}
        
        document.addEventListener('keydown', function(e) {{
            if (e.key === 'Escape') closeModal();
        }});
        
        let currentFilter = 'all';
        
        function filterByStatus(status) {{
            currentFilter = status;
            document.querySelectorAll('.filter-btn').forEach(btn => btn.classList.remove('active'));
            event.target.classList.add('active');
            filterCards();
        }}
        
        function filterCards() {{
            const search = document.getElementById('search').value.toLowerCase();
            const cards = document.querySelectorAll('.card');
            let visible = 0;
            
            cards.forEach(card => {{
                const url = card.dataset.url.toLowerCase();
                const status = card.dataset.status;
                const matchesSearch = url.includes(search);
                const matchesFilter = currentFilter === 'all' || status.startsWith(currentFilter[0]);
                
                if (matchesSearch && matchesFilter) {{
                    card.style.display = 'block';
                    visible++;
                }} else {{
                    card.style.display = 'none';
                }}
            }});
            
            document.getElementById('no-results').style.display = visible === 0 ? 'block' : 'none';
        }}
    </script>
</body>
</html>'''

    CARD_TEMPLATE = '''<div class="card" data-url="{url}" data-status="{status}">
        <img class="card-img" src="{img_path}" alt="{url}" onclick="openModal('{img_path}')" loading="lazy">
        <div class="card-body">
            <div class="card-title"><a href="{url}" target="_blank">{url}</a></div>
            <div class="card-meta">
                <span class="badge status-{status_class}">{status}</span>
                {title_badge}
            </div>
        </div>
    </div>'''

    @classmethod
    def generate(cls, screenshots_dir: Path, target: str, output_file: Path = None) -> Path:
        """Generate HTML gallery from screenshot directory"""
        if not screenshots_dir.exists():
            return None
        
        # Find all screenshots
        screenshots = list(screenshots_dir.glob("*.png")) + list(screenshots_dir.glob("*.jpg"))
        if not screenshots:
            return None
        
        cards_html = []
        unique_hosts = set()
        
        for img_path in sorted(screenshots):
            # Parse URL from filename (gowitness format: scheme-host-port.png)
            filename = img_path.stem
            
            # Try to reconstruct URL from filename
            url = cls._filename_to_url(filename)
            if not url:
                url = filename
            
            # Extract host
            try:
                from urllib.parse import urlparse
                parsed = urlparse(url)
                unique_hosts.add(parsed.netloc or url)
            except:
                unique_hosts.add(url)
            
            # Detect status code from filename or default
            status = "200"
            status_class = "2xx"
            if "-" in filename:
                parts = filename.split("-")
                for part in parts:
                    if part.isdigit() and len(part) == 3:
                        status = part
                        if status.startswith("2"):
                            status_class = "2xx"
                        elif status.startswith("3"):
                            status_class = "3xx"
                        elif status.startswith("4"):
                            status_class = "4xx"
                        elif status.startswith("5"):
                            status_class = "5xx"
                        break
            
            # Title badge (extract from filename if available)
            title_badge = ""
            
            card = cls.CARD_TEMPLATE.format(
                url=url,
                img_path=img_path.name,
                status=status,
                status_class=status_class,
                title_badge=title_badge
            )
            cards_html.append(card)
        
        # Generate full HTML
        html = cls.HTML_TEMPLATE.format(
            target=target,
            timestamp=datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            total_screenshots=len(screenshots),
            unique_hosts=len(unique_hosts),
            cards="\n".join(cards_html)
        )
        
        # Write to file
        if output_file is None:
            output_file = screenshots_dir / "gallery.html"
        
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(html)
        
        return output_file
    
    @staticmethod
    def _filename_to_url(filename: str) -> str:
        """Convert gowitness filename back to URL"""
        # gowitness format: http-example-com-8080.png or https-sub-example-com.png
        filename = filename.replace(".png", "").replace(".jpg", "")
        
        if filename.startswith("http-"):
            scheme = "http"
            rest = filename[5:]
        elif filename.startswith("https-"):
            scheme = "https"
            rest = filename[6:]
        else:
            return None
        
        # Replace dashes with dots, but handle port at end
        parts = rest.rsplit("-", 1)
        if len(parts) == 2 and parts[1].isdigit():
            host = parts[0].replace("-", ".")
            port = parts[1]
            if (scheme == "http" and port == "80") or (scheme == "https" and port == "443"):
                return f"{scheme}://{host}"
            return f"{scheme}://{host}:{port}"
        else:
            host = rest.replace("-", ".")
            return f"{scheme}://{host}"

@dataclass
class ScanContext:
    """Holds all scan data and state"""
    target: str
    mode: Mode
    output_dir: Path
    use_proxy: bool = True
    
    # Discovered assets
    subdomains: Set[str] = field(default_factory=set)
    resolved: Dict[str, List[str]] = field(default_factory=dict)
    live_hosts: Set[str] = field(default_factory=set)
    ports: Dict[str, List[int]] = field(default_factory=dict)
    urls: Set[str] = field(default_factory=set)
    js_files: Set[str] = field(default_factory=set)
    endpoints: Set[str] = field(default_factory=set)
    technologies: Dict[str, List[str]] = field(default_factory=dict)
    vulnerabilities: List[Dict] = field(default_factory=list)
    
    # Stats
    errors: List[str] = field(default_factory=list)
    start_time: datetime = field(default_factory=datetime.now)

# ============== TOOL RUNNER (YAML-DRIVEN) ==============

class ToolRunner:
    """Runs tools based on YAML pipeline configuration"""
    
    def __init__(self, pipeline_config: Dict, use_proxy: bool = True, rate_limit: int = 100, threads: int = 25):
        self.config = pipeline_config
        self.tools = pipeline_config.get("tools", {})
        self.parsers = pipeline_config.get("parsers", {})
        self.use_proxy = use_proxy and is_installed("proxychains4")
        self.rate_limit = rate_limit
        self.threads = threads
    
    def run_shell(self, cmd_str: str, timeout: int = 300, use_proxy: bool = None) -> Tuple[int, str, str]:
        """Execute a shell command string"""
        proxy = self.use_proxy if use_proxy is None else use_proxy
        if proxy and is_installed("proxychains4"):
            cmd_str = f"proxychains4 -q {cmd_str}"
        try:
            result = subprocess.run(cmd_str, shell=True, timeout=timeout, capture_output=True, text=True)
            return result.returncode, result.stdout, result.stderr
        except subprocess.TimeoutExpired:
            return -1, "", "Timeout"
        except Exception as e:
            return -1, "", str(e)
    
    def run_tool(self, tool_name: str, context: Dict) -> Tuple[bool, Any]:
        """
        Run a tool from the YAML config.
        context should contain: target, input_file, output_file, output_dir, threads, rate
        Returns: (success, result_data)
        """
        if tool_name not in self.tools:
            return False, f"Tool {tool_name} not defined in pipeline.yaml"
        
        tool_cfg = self.tools[tool_name]
        
        # Check if installed
        check_bin = tool_cfg.get("installed_check", tool_name)
        if not is_installed(check_bin):
            return False, f"{check_bin} not installed"
        
        # Build command from template
        cmd_template = tool_cfg.get("cmd", "")
        timeout = tool_cfg.get("timeout", 300)
        
        # Merge tool options with context
        options = tool_cfg.get("options", {})
        ctx = {**options, **context, "threads": self.threads, "rate": self.rate_limit}
        
        # Replace placeholders
        try:
            cmd = cmd_template.format(**ctx)
        except KeyError as e:
            return False, f"Missing placeholder: {e}"
        
        # Execute
        code, stdout, stderr = self.run_shell(cmd, timeout)
        
        if code != 0 and not stdout:
            return False, stderr or "Command failed"
        
        # Parse output based on type
        output_type = tool_cfg.get("output", "stdout_lines")
        
        if output_type == "stdout_lines":
            lines = [l.strip() for l in stdout.split('\n') if l.strip()]
            return True, set(lines)
        
        elif output_type == "json_lines":
            results = []
            parser_name = tool_cfg.get("parser")
            parser = self.parsers.get(parser_name, {}) if parser_name else {}
            
            for line in stdout.split('\n'):
                if line.strip():
                    try:
                        data = json.loads(line)
                        results.append(data)
                    except json.JSONDecodeError:
                        pass
            return True, results
        
        elif output_type == "file":
            output_file = context.get("output_file")
            if output_file and Path(output_file).exists():
                return True, Path(output_file)
            return True, None
        
        elif output_type == "directory":
            return True, context.get("output_dir")
        
        return True, stdout
    
    def parse_json_results(self, tool_name: str, results: List[Dict]) -> Any:
        """Parse JSON results based on tool parser config"""
        parser_name = self.tools.get(tool_name, {}).get("parser")
        if not parser_name:
            return results
        
        parser = self.parsers.get(parser_name, {})
        
        if parser_name == "dnsx":
            # Returns {host: [ips]}
            resolved = {}
            for r in results:
                host = r.get(parser.get("host_field", "host"), "")
                ips = r.get(parser.get("data_field", "a"), [])
                if host and ips:
                    resolved[host] = ips
            return resolved
        
        elif parser_name == "naabu":
            # Returns {host: [ports]}
            ports = {}
            for r in results:
                host = r.get(parser.get("host_field", "host"), "")
                port = r.get(parser.get("port_field", "port"), 0)
                if host and port:
                    ports.setdefault(host, []).append(port)
            return ports
        
        elif parser_name == "httpx":
            # Returns (live_urls, technologies)
            live = set()
            techs = {}
            for r in results:
                url = r.get(parser.get("url_field", "url"), "")
                if url:
                    live.add(url)
                    tech = r.get(parser.get("tech_field", "tech"), [])
                    if tech:
                        techs[url] = tech
            return (live, techs)
        
        return results

# ============== SCAN ENGINE (YAML-DRIVEN) ==============

class MacaronEngine:
    """Main scan orchestrator using YAML pipeline configuration"""
    
    def __init__(self, use_proxy: bool = True, rate: int = 100, threads: int = 25, quiet: bool = False, mode: str = "wide"):
        self.pipeline_config = load_pipeline_config()
        self.main_config = load_config()
        self.runner = ToolRunner(self.pipeline_config, use_proxy, rate, threads)
        self.quiet = quiet
        self.running = True
        self.notifier = DiscordNotifier()
        self.rate = rate
        self.threads = threads
        
        # Ensure directories
        for d in [DATA_DIR, CONFIG_DIR, STATE_DIR, LOGS_DIR, WORDLISTS_DIR]:
            ensure_dir(d)
        
        # Copy bundled configs to user config if not exists
        if not PIPELINE_FILE.exists() and BUNDLED_PIPELINE.exists():
            shutil.copy(BUNDLED_PIPELINE, PIPELINE_FILE)
        if not CONFIG_FILE.exists() and BUNDLED_CONFIG.exists():
            shutil.copy(BUNDLED_CONFIG, CONFIG_FILE)
        
        # Create default wordlist if missing
        self._ensure_wordlist()
        
        signal.signal(signal.SIGINT, self._handle_interrupt)
        signal.signal(signal.SIGTERM, self._handle_interrupt)
    
    def _ensure_wordlist(self):
        """Create a basic wordlist if none exists"""
        common_wordlist = WORDLISTS_DIR / "common.txt"
        if not common_wordlist.exists():
            # Basic wordlist for content discovery
            basic_words = [
                "admin", "api", "app", "assets", "backup", "bin", "cache", "cgi-bin",
                "config", "console", "css", "dashboard", "data", "db", "debug", "dev",
                "docs", "download", "downloads", "files", "fonts", "graphql", "help",
                "home", "images", "img", "includes", "index", "js", "json", "lib",
                "login", "logout", "logs", "mail", "media", "mobile", "panel", "php",
                "private", "public", "rest", "robots.txt", "scripts", "search", "server",
                "sitemap.xml", "src", "staging", "static", "status", "storage", "swagger",
                "sys", "system", "temp", "test", "tmp", "upload", "uploads", "user",
                "users", "v1", "v2", "vendor", "web", "webmail", "wp-admin", "wp-content",
                ".git", ".env", ".htaccess", "backup.sql", "database.sql", "dump.sql"
            ]
            with open(common_wordlist, 'w') as f:
                f.write('\n'.join(basic_words))
    
    def _handle_interrupt(self, signum, frame):
        self.running = False
        if console:
            console.print("\n[yellow]‚ö† Interrupt received, stopping gracefully...[/]")
    
    def scan(self, targets: List[str], mode: str = "wide", resume: bool = False) -> Dict:
        """Execute scan using YAML pipeline definition"""
        start = datetime.now()
        self.notifier.scan_start(targets, mode)
        
        stats = {
            "mode": mode,
            "targets": len(targets),
            "subdomains": 0,
            "live_hosts": 0,
            "ports": 0,
            "urls": 0,
            "vulnerabilities": 0,
            "errors": 0,
            "new_subdomains": 0,
            "new_live_hosts": 0,
            "new_vulnerabilities": 0
        }
        
        if console and not self.quiet:
            console.print(BANNER.format(version=VERSION))
        
        # Get pipeline from config
        pipelines = self.pipeline_config.get("pipelines", {})
        if mode not in pipelines:
            if console:
                console.print(f"[red]Pipeline '{mode}' not found in pipeline.yaml[/]")
            return stats
        
        pipeline = pipelines[mode]
        stages = pipeline.get("stages", [])
        
        for i, target in enumerate(targets):
            if not self.running:
                break
            
            output_dir = DATA_DIR / sanitize(target)
            ensure_dir(output_dir)
            
            # Initialize state manager for resume capability
            state_mgr = StateManager(target)
            diff_tracker = DiffTracker(output_dir)
            
            # Check for resumable state
            start_stage = 0
            if resume and state_mgr.has_state():
                saved_state = state_mgr.load_state()
                if saved_state:
                    start_stage = saved_state.get("current_stage", 0)
                    # Restore context from saved state
                    ctx = {
                        "target": target,
                        "subdomains": saved_state.get("subdomains", {target}),
                        "resolved": saved_state.get("resolved", {}),
                        "ports": saved_state.get("ports", {}),
                        "live_hosts": saved_state.get("live_hosts", set()),
                        "urls": saved_state.get("urls", set()),
                        "js_files": saved_state.get("js_files", set()),
                        "vulnerabilities": saved_state.get("vulnerabilities", []),
                        "technologies": saved_state.get("technologies", {}),
                        "errors": saved_state.get("errors", []),
                        "output_dir": output_dir
                    }
                    if console and not self.quiet:
                        console.print(f"\n[yellow]‚ü≥ Resuming from stage {start_stage + 1}...[/]\n")
                else:
                    ctx = self._init_context(target, output_dir)
            else:
                ctx = self._init_context(target, output_dir)
            
            if console and not self.quiet:
                console.print(f"\n[bold cyan]‚îÅ‚îÅ‚îÅ Target {i+1}/{len(targets)}: {target} ‚îÅ‚îÅ‚îÅ[/]\n")
            
            # Run each stage in the pipeline
            for stage_idx, stage in enumerate(stages):
                if not self.running:
                    # Save state for resume on interrupt
                    state_mgr.save_state(ctx, stage_idx, mode)
                    if console and not self.quiet:
                        console.print(f"\n[yellow]üíæ State saved. Resume with --resume flag[/]")
                    break
                
                # Skip already completed stages if resuming
                if stage_idx < start_stage:
                    continue
                
                if not stage.get("enabled", True):
                    continue
                
                ctx = self._run_pipeline_stage(stage, ctx)
                
                # Update diff tracker after each stage
                output_to = stage.get("output_to", "")
                if output_to == "subdomains":
                    diff_tracker.update("subdomains", ctx.get("subdomains", set()))
                elif output_to == "live_hosts":
                    diff_tracker.update("live_hosts", ctx.get("live_hosts", set()))
                elif output_to == "urls":
                    diff_tracker.update("urls", ctx.get("urls", set()))
                elif output_to == "ports":
                    port_set = {f"{h}:{p}" for h, ports in ctx.get("ports", {}).items() for p in ports}
                    diff_tracker.update("ports", port_set)
                elif output_to == "vulnerabilities":
                    diff_tracker.update("vulnerabilities", ctx.get("vulnerabilities", []))
                
                # Save state after each stage for resume capability
                state_mgr.save_state(ctx, stage_idx + 1, mode)
            
            # Compute diff with previous scan
            diff = diff_tracker.compute_diff()
            
            # Notify on new findings
            if diff["new_subdomains"] > 0 or diff["new_live_hosts"] > 0:
                self.notifier.new_assets(target, diff)
            
            # Notify on new vulnerabilities
            for vuln in diff_tracker.new_assets.get("vulnerabilities", []):
                self.notifier.vulnerability(
                    vuln.get("name", "Unknown"),
                    vuln.get("severity", "info"),
                    vuln.get("host", target)
                )
            
            # Save diff report and history
            diff_tracker.save_diff_report()
            diff_tracker.save()
            
            # Generate screenshot gallery if screenshots exist
            screenshots_dir = output_dir / "gowitness"
            if screenshots_dir.exists():
                gallery_path = ScreenshotGallery.generate(screenshots_dir, target)
                if gallery_path and console and not self.quiet:
                    console.print(f"  [green]‚úì[/] Screenshot gallery: [dim]{gallery_path}[/]")
            
            # Update stats
            stats["subdomains"] += len(ctx.get("subdomains", []))
            stats["live_hosts"] += len(ctx.get("live_hosts", []))
            stats["ports"] += sum(len(p) for p in ctx.get("ports", {}).values())
            stats["urls"] += len(ctx.get("urls", []))
            stats["vulnerabilities"] += len(ctx.get("vulnerabilities", []))
            stats["errors"] += len(ctx.get("errors", []))
            stats["new_subdomains"] += diff["new_subdomains"]
            stats["new_live_hosts"] += diff["new_live_hosts"]
            stats["new_vulnerabilities"] += diff["new_vulnerabilities"]
            
            self._save_results(ctx, diff)
            
            # Clear state after successful completion
            if self.running:
                state_mgr.clear_state()
        
        stats["duration"] = str(datetime.now() - start).split('.')[0]
        stats["status"] = "completed" if self.running else "interrupted"
        
        self.notifier.scan_complete(stats)
        self._print_summary(stats)
        
        return stats
    
    def _init_context(self, target: str, output_dir: Path) -> Dict:
        """Initialize a fresh scan context"""
        return {
            "target": target,
            "subdomains": {target},  # Include target domain by default
            "resolved": {},
            "ports": {},
            "live_hosts": set(),
            "urls": set(),
            "js_files": set(),
            "vulnerabilities": [],
            "technologies": {},
            "errors": [],
            "output_dir": output_dir
        }
    
    def _run_pipeline_stage(self, stage: Dict, ctx: Dict) -> Dict:
        """Run a single pipeline stage from YAML config"""
        name = stage.get("name", "Unknown")
        emoji = stage.get("emoji", "‚ñ∂")
        tools = stage.get("tools", [])
        input_from = stage.get("input_from", "target")
        output_to = stage.get("output_to", "")
        limit = stage.get("limit", None)
        
        if not tools:
            return ctx
        
        # Determine input data
        if input_from == "target":
            input_data = [ctx["target"]]
        elif input_from == "subdomains":
            input_data = list(ctx.get("subdomains", set()))
        elif input_from == "resolved":
            input_data = list(ctx.get("resolved", {}).keys())
        elif input_from == "live_hosts":
            input_data = list(ctx.get("live_hosts", set()))
        elif input_from == "subdomains+ports":
            # Combine subdomains with non-standard ports
            input_data = list(ctx.get("subdomains", set()))
            for host, ports in ctx.get("ports", {}).items():
                for port in ports:
                    if port not in (80, 443):
                        input_data.append(f"{host}:{port}")
        elif input_from == "urls":
            input_data = list(ctx.get("urls", set()))
        else:
            input_data = [ctx["target"]]
        
        if not input_data:
            return ctx
        
        # Apply limit
        if limit and len(input_data) > limit:
            input_data = input_data[:limit]
        
        results = {}
        
        # Progress display
        if console and not self.quiet:
            with Progress(
                SpinnerColumn(),
                TextColumn(f"[bold cyan]{emoji} {name}[/]"),
                BarColumn(bar_width=30),
                TaskProgressColumn(),
                TextColumn("‚Ä¢"),
                TimeElapsedColumn(),
                console=console,
                transient=True
            ) as progress:
                task = progress.add_task("", total=len(tools))
                
                for tool_name in tools:
                    if not self.running:
                        break
                    
                    progress.update(task, description=f"[dim]{tool_name}[/]")
                    result = self._execute_tool(tool_name, input_data, ctx)
                    if result is not None:
                        results[tool_name] = result
                    progress.advance(task)
        else:
            for tool_name in tools:
                if not self.running:
                    break
                result = self._execute_tool(tool_name, input_data, ctx)
                if result is not None:
                    results[tool_name] = result
        
        # Merge results into context based on output_to
        ctx = self._merge_results(results, output_to, ctx)
        
        # Save intermediate results
        self._save_stage_output(output_to, ctx)
        
        # Print stage completion
        count = self._get_count(output_to, ctx)
        if count > 0 and console and not self.quiet:
            color = "red" if output_to == "vulnerabilities" else "green"
            console.print(f"  [{color}]‚úì[/] {output_to}: [bold]{count}[/]")
        
        return ctx
    
    def _execute_tool(self, tool_name: str, input_data: List[str], ctx: Dict) -> Any:
        """Execute a single tool from YAML config"""
        tool_cfg = self.pipeline_config.get("tools", {}).get(tool_name, {})
        if not tool_cfg:
            return None
        
        input_type = tool_cfg.get("input", "target")
        
        # Create temp file if needed
        temp_file = None
        if input_type == "file":
            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False) as f:
                f.write('\n'.join(input_data))
                temp_file = f.name
        
        output_file = None
        if tool_cfg.get("output") in ("json_lines", "file"):
            output_file = str(ctx["output_dir"] / f"{tool_name}_output.json")
        
        # Build context for tool execution
        tool_output_dir = ctx["output_dir"] / tool_name
        ensure_dir(tool_output_dir)
        
        tool_ctx = {
            "target": input_data[0] if input_data else ctx["target"],
            "input_file": temp_file or "",
            "output_file": output_file or "",
            "output_dir": str(tool_output_dir),
            "wordlist": str(Path(tool_cfg.get("options", {}).get("wordlist", "~/.macaron/wordlists/common.txt")).expanduser()),
            "severity": tool_cfg.get("options", {}).get("severity", "critical,high,medium"),
            "depth": tool_cfg.get("options", {}).get("depth", 3),
        }
        
        try:
            success, result = self.runner.run_tool(tool_name, tool_ctx)
            
            if not success:
                ctx["errors"].append(f"{tool_name}: {result}")
                return None
            
            # Parse JSON results if needed
            if tool_cfg.get("output") == "json_lines" and isinstance(result, list):
                return self.runner.parse_json_results(tool_name, result)
            
            return result
            
        except Exception as e:
            ctx["errors"].append(f"{tool_name}: {e}")
            return None
        finally:
            if temp_file:
                Path(temp_file).unlink(missing_ok=True)
    
    def _merge_results(self, results: Dict, output_to: str, ctx: Dict) -> Dict:
        """Merge tool results into context"""
        for tool_name, result in results.items():
            if result is None:
                continue
            
            if output_to == "subdomains":
                if isinstance(result, (set, list)):
                    # Filter to only include subdomains of target
                    target = ctx["target"]
                    ctx["subdomains"].update(s.lower() for s in result if target in s.lower())
            
            elif output_to == "resolved":
                if isinstance(result, dict):
                    ctx["resolved"].update(result)
            
            elif output_to == "ports":
                if isinstance(result, dict):
                    for host, ports in result.items():
                        ctx["ports"].setdefault(host, []).extend(ports)
            
            elif output_to == "live_hosts":
                if isinstance(result, tuple):  # httpx returns (live, techs)
                    live, techs = result
                    ctx["live_hosts"].update(live)
                    ctx["technologies"].update(techs)
                elif isinstance(result, (set, list)):
                    ctx["live_hosts"].update(result)
            
            elif output_to == "urls":
                if isinstance(result, (set, list)):
                    ctx["urls"].update(result)
            
            elif output_to == "js_files":
                if isinstance(result, (set, list)):
                    ctx["js_files"].update(r for r in result if '.js' in r.lower())
            
            elif output_to == "vulnerabilities":
                if isinstance(result, list) and result:
                    ctx["vulnerabilities"].extend(result)
                else:
                    # Read from nuclei output file only if no parsed results
                    vuln_file = ctx["output_dir"] / "nuclei_output.json"
                    if vuln_file.exists():
                        with open(vuln_file) as f:
                            for line in f:
                                if line.strip():
                                    try:
                                        v = json.loads(line)
                                        ctx["vulnerabilities"].append({
                                            "host": v.get("host", ""),
                                            "name": v.get("info", {}).get("name", ""),
                                            "severity": v.get("info", {}).get("severity", "info"),
                                            "template": v.get("template-id", ""),
                                        })
                                    except json.JSONDecodeError:
                                        pass
        
        return ctx
    
    def _save_stage_output(self, output_to: str, ctx: Dict):
        """Save stage output to files"""
        output_dir = ctx["output_dir"]
        
        if output_to == "subdomains" and ctx.get("subdomains"):
            save_list(output_dir / "subdomains.txt", ctx["subdomains"])
        elif output_to == "resolved" and ctx.get("resolved"):
            save_list(output_dir / "resolved.txt", [f"{h}: {', '.join(map(str, ips))}" for h, ips in ctx["resolved"].items()])
        elif output_to == "ports" and ctx.get("ports"):
            save_list(output_dir / "ports.txt", [f"{h}:{p}" for h, ports in ctx["ports"].items() for p in ports])
        elif output_to == "live_hosts" and ctx.get("live_hosts"):
            save_list(output_dir / "live_hosts.txt", ctx["live_hosts"])
            if ctx.get("technologies"):
                save_list(output_dir / "technologies.txt", [f"{h}: {', '.join(t)}" for h, t in ctx["technologies"].items()])
        elif output_to == "urls" and ctx.get("urls"):
            save_list(output_dir / "urls.txt", ctx["urls"])
        elif output_to == "js_files" and ctx.get("js_files"):
            save_list(output_dir / "js_files.txt", ctx["js_files"])
    
    def _get_count(self, output_to: str, ctx: Dict) -> int:
        """Get count of items in output"""
        if output_to == "subdomains":
            return len(ctx.get("subdomains", []))
        elif output_to == "resolved":
            return len(ctx.get("resolved", {}))
        elif output_to == "ports":
            return sum(len(p) for p in ctx.get("ports", {}).values())
        elif output_to == "live_hosts":
            return len(ctx.get("live_hosts", []))
        elif output_to == "urls":
            return len(ctx.get("urls", []))
        elif output_to == "js_files":
            return len(ctx.get("js_files", []))
        elif output_to == "vulnerabilities":
            return len(ctx.get("vulnerabilities", []))
        elif output_to == "screenshots":
            ss_dir = ctx["output_dir"] / "gowitness"
            return len(list(ss_dir.glob("*.png"))) if ss_dir.exists() else 0
        return 0
    
    def _save_results(self, ctx: Dict, diff: Dict = None):
        """Save final scan summary with diff information"""
        summary = {
            "target": ctx["target"],
            "scanned_at": get_timestamp(),
            "stats": {
                "subdomains": len(ctx.get("subdomains", [])),
                "resolved": len(ctx.get("resolved", {})),
                "live_hosts": len(ctx.get("live_hosts", [])),
                "ports": sum(len(p) for p in ctx.get("ports", {}).values()),
                "urls": len(ctx.get("urls", [])),
                "js_files": len(ctx.get("js_files", [])),
                "vulnerabilities": len(ctx.get("vulnerabilities", []))
            },
            "vulnerabilities": ctx.get("vulnerabilities", []),
            "errors": ctx.get("errors", [])
        }
        if diff:
            summary["diff"] = {
                "new_subdomains": diff.get("new_subdomains", 0),
                "new_live_hosts": diff.get("new_live_hosts", 0),
                "new_urls": diff.get("new_urls", 0),
                "new_ports": diff.get("new_ports", 0),
                "new_vulnerabilities": diff.get("new_vulnerabilities", 0),
                "previous_scan": diff.get("last_scan", "Never")
            }
        with open(ctx["output_dir"] / "summary.json", 'w') as f:
            json.dump(summary, f, indent=2)
    
    def _print_summary(self, stats: Dict):
        """Print scan summary with diff information"""
        if not console or self.quiet:
            return
        
        table = Table(title="Scan Results", box=box.ROUNDED, border_style="cyan")
        table.add_column("Metric", style="cyan")
        table.add_column("Total", style="bold white", justify="right")
        table.add_column("New", style="green", justify="right")
        
        table.add_row("Mode", stats["mode"], "")
        table.add_row("Duration", stats["duration"], "")
        
        # Show new counts if available
        new_subs = stats.get("new_subdomains", 0)
        new_live = stats.get("new_live_hosts", 0)
        new_vulns = stats.get("new_vulnerabilities", 0)
        
        table.add_row("Subdomains", str(stats["subdomains"]), f"+{new_subs}" if new_subs else "-")
        table.add_row("Live Hosts", str(stats["live_hosts"]), f"+{new_live}" if new_live else "-")
        table.add_row("Open Ports", str(stats["ports"]), "")
        table.add_row("URLs", str(stats["urls"]), "")
        
        vuln_style = "bold red" if stats["vulnerabilities"] > 0 else "green"
        new_vuln_str = f"[bold red]+{new_vulns}[/]" if new_vulns else "-"
        table.add_row("Vulnerabilities", f"[{vuln_style}]{stats['vulnerabilities']}[/]", new_vuln_str)
        
        console.print()
        console.print(table)
        
        # Show prominent alert if new findings
        if new_subs > 0 or new_live > 0 or new_vulns > 0:
            console.print(f"\n[bold green]üÜï NEW FINDINGS:[/] {new_subs} subdomains, {new_live} live hosts, {new_vulns} vulns")
            console.print(f"[dim]See diff_report.txt for details[/]")
        
        console.print(f"\n[dim]Results: {DATA_DIR}[/]")
        console.print(f"[dim]Config:  {PIPELINE_FILE}[/]")

# ============== DISCORD NOTIFIER ==============

class DiscordNotifier:
    """Discord webhook notifications with diff alerts"""
    
    def __init__(self):
        config = load_config().get("discord", {})
        self.enabled = config.get("enabled", False)
        self.webhook_url = config.get("webhook_url", "")
        self.notify_on = config.get("notify_on", ["scan_start", "scan_complete", "vulnerability", "new_assets"])
    
    def _send(self, title: str, msg: str, color: int = 0x3498db):
        if not self.enabled or not self.webhook_url:
            return
        try:
            import urllib.request
            payload = json.dumps({
                "embeds": [{
                    "title": title,
                    "description": msg[:4000],
                    "color": color,
                    "footer": {"text": "Macaron v2"},
                    "timestamp": get_timestamp()
                }]
            }).encode()
            req = urllib.request.Request(self.webhook_url, data=payload, headers={"Content-Type": "application/json"})
            urllib.request.urlopen(req, timeout=10)
        except:
            pass
    
    def scan_start(self, targets: List[str], mode: str):
        if "scan_start" in self.notify_on:
            self._send("üöÄ Scan Started", f"**Mode:** {mode}\n**Targets:** {', '.join(targets[:5])}", 0x3498db)
    
    def scan_complete(self, stats: Dict):
        if "scan_complete" in self.notify_on:
            msg = f"**Duration:** {stats.get('duration')}\n"
            msg += f"**Subdomains:** {stats.get('subdomains')} (+{stats.get('new_subdomains', 0)} new)\n"
            msg += f"**Live Hosts:** {stats.get('live_hosts')} (+{stats.get('new_live_hosts', 0)} new)\n"
            msg += f"**Vulnerabilities:** {stats.get('vulnerabilities')} (+{stats.get('new_vulnerabilities', 0)} new)"
            self._send("‚úÖ Scan Complete", msg, 0x2ecc71)
    
    def vulnerability(self, name: str, severity: str, target: str):
        if "vulnerability" in self.notify_on:
            colors = {"critical": 0xff0000, "high": 0xff6600, "medium": 0xffff00}
            self._send(f"‚ö†Ô∏è {severity.upper()}: {name}", f"**Target:** {target}", colors.get(severity.lower(), 0x7289da))
    
    def new_assets(self, target: str, diff: Dict):
        """Notify about new assets discovered"""
        if "new_assets" not in self.notify_on:
            return
        
        new_subs = diff.get("new_subdomains", 0)
        new_live = diff.get("new_live_hosts", 0)
        new_vulns = diff.get("new_vulnerabilities", 0)
        
        if new_subs == 0 and new_live == 0 and new_vulns == 0:
            return
        
        msg = f"**Target:** {target}\n"
        msg += f"**Previous Scan:** {diff.get('last_scan', 'Never')}\n\n"
        
        if new_subs > 0:
            msg += f"üîç **+{new_subs} new subdomains**\n"
        if new_live > 0:
            msg += f"üåê **+{new_live} new live hosts**\n"
        if new_vulns > 0:
            msg += f"üéØ **+{new_vulns} new vulnerabilities**\n"
        
        color = 0xff0000 if new_vulns > 0 else 0x00ff00
        self._send("üÜï New Assets Discovered", msg, color)

# ============== CLI COMMANDS ==============

def validate_target(target: str) -> Optional[str]:
    """Validate and normalize a target. Returns normalized target or None if invalid."""
    target = target.strip().lower()
    if not target:
        return None
    
    # Remove protocol for validation
    clean = target.replace("https://", "").replace("http://", "").split("/")[0].split(":")[0]
    
    # Basic domain/IP validation
    if not clean:
        return None
    
    # Check for valid domain pattern (letters, numbers, dots, hyphens)
    if not re.match(r'^[a-z0-9]([a-z0-9\-]*[a-z0-9])?(\.[a-z0-9]([a-z0-9\-]*[a-z0-9])?)*$', clean):
        # Could be an IP address
        if not re.match(r'^\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}$', clean):
            return None
    
    return target

def validate_targets(targets: List[str]) -> Tuple[List[str], List[str]]:
    """Validate a list of targets. Returns (valid_targets, invalid_targets)."""
    valid = []
    invalid = []
    for t in targets:
        normalized = validate_target(t)
        if normalized:
            valid.append(normalized)
        else:
            invalid.append(t)
    return valid, invalid

def cmd_scan(args):
    """Run a scan"""
    targets = []
    
    # File takes priority if specified
    if args.file:
        file_path = Path(args.file)
        if not file_path.exists():
            console.print(f"[red]‚úó File not found: {args.file}[/]") if console else print(f"File not found: {args.file}")
            return 1
        targets = load_list(file_path)
    elif args.target:
        targets = args.target if isinstance(args.target, list) else [args.target]
    elif args.stdin:
        targets = [l.strip() for l in sys.stdin if l.strip()]
    
    if not targets:
        console.print("[red]‚úó No targets provided[/]") if console else print("No targets")
        console.print("[dim]Usage: macaron -s target.com OR macaron -F targets.txt[/]") if console else None
        return 1
    
    # Validate targets
    valid_targets, invalid_targets = validate_targets(targets)
    
    if invalid_targets:
        if console:
            console.print(f"[yellow]‚ö† Skipping {len(invalid_targets)} invalid target(s):[/]")
            for inv in invalid_targets[:5]:
                console.print(f"  [dim]‚Ä¢ {inv}[/]")
            if len(invalid_targets) > 5:
                console.print(f"  [dim]... and {len(invalid_targets) - 5} more[/]")
    
    if not valid_targets:
        console.print("[red]‚úó No valid targets to scan[/]") if console else print("No valid targets")
        return 1
    
    targets = valid_targets
    
    # Validate rate limit
    if args.rate is not None and args.rate < 1:
        console.print("[red]‚úó Rate limit must be at least 1[/]") if console else print("Invalid rate")
        return 1
    
    # Validate threads
    if args.threads is not None and args.threads < 1:
        console.print("[red]‚úó Threads must be at least 1[/]") if console else print("Invalid threads")
        return 1
    
    # Check for resumable scans if --resume flag
    if args.resume:
        for target in targets:
            state_mgr = StateManager(target)
            info = state_mgr.get_resume_info()
            if info:
                if console:
                    console.print(f"[yellow]‚ü≥ Found saved state for {target}[/]")
                    console.print(f"  [dim]Mode: {info['mode']}, Stage: {info['stage']}, Saved: {info['saved_at']}[/]")
                    console.print(f"  [dim]Data: {info['subdomains']} subdomains, {info['live_hosts']} live hosts[/]")
    
    # Mode selection (now supports custom modes from pipeline.yaml)
    if args.mode:
        mode = args.mode
    elif args.fast:
        mode = "fast"
    elif args.narrow:
        mode = "narrow"
    else:
        mode = "wide"
    
    # Load config for defaults
    config = load_config()
    rate_cfg = config.get("rate_limits", {})
    
    # Rate limiting
    if args.slow:
        rate = rate_cfg.get("slow_mode_rate", 10)
        threads = rate_cfg.get("slow_mode_threads", 5)
    else:
        rate = args.rate or rate_cfg.get("global_requests_per_second", 100)
        threads = args.threads or config.get("general", {}).get("default_threads", 25)
    
    engine = MacaronEngine(
        use_proxy=not args.no_proxy,
        rate=rate,
        threads=threads,
        quiet=args.quiet
    )
    
    stats = engine.scan(targets, mode=mode, resume=args.resume)
    return 0 if stats.get("status") == "completed" else 1

def cmd_status(args):
    """Show status"""
    if not console:
        print("Status requires rich library")
        return 1
    
    console.print(BANNER.format(version=VERSION))
    
    # Data summary
    if DATA_DIR.exists():
        table = Table(title="Scan Data", box=box.ROUNDED)
        table.add_column("Domain", style="cyan")
        table.add_column("Subdomains", justify="right")
        table.add_column("Live", justify="right")
        table.add_column("Vulns", justify="right", style="red")
        
        for d in sorted(DATA_DIR.iterdir())[:10]:
            if d.is_dir():
                subs = len(load_list(d / "subdomains.txt"))
                live = len(load_list(d / "live_hosts.txt"))
                vulns = 0
                vuln_file = d / "nuclei.json"
                if vuln_file.exists():
                    with open(vuln_file) as f:
                        vulns = len([l for l in f if l.strip()])
                table.add_row(d.name, str(subs), str(live), str(vulns))
        
        console.print(table)
    else:
        console.print("[dim]No scan data yet[/]")
    
    return 0

def cmd_show(args):
    """Show results"""
    if not console:
        return 1
    
    domain = args.domain
    what = args.what or "all"
    limit = args.limit or 50
    
    targets = []
    if DATA_DIR.exists():
        for d in DATA_DIR.iterdir():
            if d.is_dir() and (not domain or domain.lower() in d.name.lower()):
                targets.append(d)
    
    if not targets:
        console.print(f"[yellow]No results found[/]")
        return 1
    
    for target_dir in targets:
        console.print(f"\n[bold cyan]{'‚ïê'*50}[/]")
        console.print(f"[bold cyan] {target_dir.name}[/]")
        console.print(f"[bold cyan]{'‚ïê'*50}[/]")
        
        # Show diff report if requested
        if what == "diff":
            diff_file = target_dir / "diff_report.txt"
            if diff_file.exists():
                console.print(f"\n[bold green]üÜï DIFF REPORT[/]")
                with open(diff_file) as f:
                    console.print(f.read())
            else:
                console.print(f"\n[dim]No diff report found. Run a scan twice to generate.[/]")
            continue
        
        files = {
            "subdomains": ("subdomains.txt", "üîç"),
            "live": ("live_hosts.txt", "üåê"),
            "ports": ("ports.txt", "üîå"),
            "urls": ("urls.txt", "üîó"),
            "js": ("js_files.txt", "üìú"),
        }
        
        for key, (filename, emoji) in files.items():
            if what not in ["all", key]:
                continue
            filepath = target_dir / filename
            if filepath.exists():
                items = load_list(filepath)
                console.print(f"\n[bold]{emoji} {key.upper()}[/] ({len(items)})")
                for item in items[:limit]:
                    console.print(f"  [dim]{item}[/]")
                if len(items) > limit:
                    console.print(f"  [dim]... and {len(items) - limit} more[/]")
        
        # Vulnerabilities
        if what in ["all", "vulns"]:
            vuln_file = target_dir / "nuclei.json"
            if vuln_file.exists():
                vulns = []
                with open(vuln_file) as f:
                    for line in f:
                        if line.strip():
                            try:
                                vulns.append(json.loads(line))
                            except:
                                pass
                if vulns:
                    console.print(f"\n[bold red]üéØ VULNERABILITIES[/] ({len(vulns)})")
                    sev_colors = {"critical": "bold red", "high": "red", "medium": "yellow", "low": "green"}
                    for v in vulns[:limit]:
                        sev = v.get("info", {}).get("severity", "info")
                        name = v.get("info", {}).get("name", v.get("template-id", ""))
                        color = sev_colors.get(sev, "dim")
                        console.print(f"  [{color}][{sev.upper():8}][/] {name}")
    
    return 0

def cmd_gallery(args):
    """Generate screenshot gallery for a domain"""
    if not args.domain:
        console.print("[red]‚úó Please specify a domain with -d[/]") if console else print("Specify domain")
        return 1
    
    # Find the target directory
    target_dir = None
    if DATA_DIR.exists():
        for d in DATA_DIR.iterdir():
            if d.is_dir() and args.domain.lower() in d.name.lower():
                target_dir = d
                break
    
    if not target_dir:
        console.print(f"[red]‚úó No data found for domain: {args.domain}[/]") if console else print("Domain not found")
        return 1
    
    screenshots_dir = target_dir / "gowitness"
    if not screenshots_dir.exists():
        console.print(f"[yellow]No screenshots found for {args.domain}[/]") if console else print("No screenshots")
        return 1
    
    gallery_path = ScreenshotGallery.generate(screenshots_dir, args.domain)
    if gallery_path:
        console.print(f"[green]‚úì Gallery generated: {gallery_path}[/]") if console else print(f"Gallery: {gallery_path}")
        console.print(f"[dim]Open in browser: file://{gallery_path}[/]") if console else None
        return 0
    else:
        console.print(f"[red]‚úó Failed to generate gallery[/]") if console else print("Failed")
        return 1

def cmd_tools(args):
    """List tools"""
    if not console:
        return 1
    
    categories = {
        "Subdomain": ["subfinder", "amass", "assetfinder", "findomain", "github-subdomains"],
        "Permutation": ["altdns", "dnsgen", "shuffledns", "puredns"],
        "DNS": ["dnsx", "massdns", "dnsrecon", "hakrevdns"],
        "ASN/IP": ["asnmap", "mapcidr"],
        "Ports": ["naabu", "masscan", "nmap"],
        "HTTP": ["httpx", "httprobe"],
        "Fingerprint": ["whatweb", "webanalyze", "favfreak"],
        "URLs": ["gau", "waybackurls", "katana", "hakrawler", "gospider"],
        "Parameters": ["paramspider", "arjun", "x8"],
        "API": ["kr"],
        "JS": ["getJS", "subjs", "linkfinder"],
        "Content": ["ffuf", "feroxbuster"],
        "Cloud": ["cloud_enum", "s3scanner"],
        "Takeover": ["subjack"],
        "OSINT": ["theHarvester", "emailfinder", "shodan"],
        "Screenshots": ["gowitness", "eyewitness"],
        "Utils": ["proxychains4", "jq", "curl"]
    }
    
    table = Table(title="Installed Tools", box=box.ROUNDED, border_style="cyan")
    table.add_column("Category", style="cyan")
    table.add_column("Tool")
    table.add_column("Status", justify="center")
    
    total, installed = 0, 0
    for cat, tools in categories.items():
        for tool in tools:
            total += 1
            if is_installed(tool):
                installed += 1
                table.add_row(cat, tool, "[green]‚úì[/]")
            else:
                table.add_row(cat, tool, "[red]‚úó[/]")
    
    console.print(table)
    pct = int((installed / total) * 100) if total else 0
    color = "green" if pct >= 70 else ("yellow" if pct >= 40 else "red")
    console.print(f"\n[{color}]{installed}/{total} ({pct}%) installed[/]")
    
    if installed < 10:
        console.print("\n[yellow]Tip:[/] Run 'sudo macaron -I' to install tools")
    
    return 0

def cmd_config(args):
    """Config management"""
    config = load_config()
    
    if args.webhook:
        config["discord"]["webhook_url"] = args.webhook
        config["discord"]["enabled"] = True
        save_config(config)
        if console:
            console.print("[green]‚úì Discord webhook configured[/]")
        if args.test:
            DiscordNotifier().scan_start(["test.com"], "test")
            console.print("[green]‚úì Test notification sent[/]") if console else None
    elif args.show:
        if console:
            console.print(f"\n[bold cyan]Configuration Files:[/]")
            console.print(f"  Main Config:     {CONFIG_FILE}")
            console.print(f"  Pipeline Config: {PIPELINE_FILE}")
            console.print(f"\n[bold cyan]Current Config:[/]")
            console.print_json(json.dumps(config, indent=2))
        else:
            print(f"Config: {CONFIG_FILE}")
            print(f"Pipeline: {PIPELINE_FILE}")
            print(json.dumps(config, indent=2))
    else:
        # Default: show config paths
        if console:
            console.print(f"\n[bold cyan]Configuration Files:[/]")
            console.print(f"  [dim]Main config (API keys, rate limits, discord):[/]")
            console.print(f"    {CONFIG_FILE}")
            console.print(f"  [dim]Pipeline config (scan modes, tools, stages):[/]")
            console.print(f"    {PIPELINE_FILE}")
            console.print(f"\n[dim]Use --show to view current config, --webhook URL to set Discord[/]")
        else:
            print(f"Config: {CONFIG_FILE}")
            print(f"Pipeline: {PIPELINE_FILE}")
    
    return 0

def cmd_export(args):
    """Export results"""
    output = Path(args.output) if args.output else Path(f"macaron_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json")
    
    data = {"exported_at": get_timestamp(), "targets": {}}
    
    if DATA_DIR.exists():
        for d in DATA_DIR.iterdir():
            if d.is_dir():
                if args.domain and args.domain not in d.name:
                    continue
                target_data = {"name": d.name}
                for f in ["subdomains.txt", "live_hosts.txt", "urls.txt", "ports.txt"]:
                    fp = d / f
                    if fp.exists():
                        target_data[f.replace(".txt", "")] = load_list(fp)
                data["targets"][d.name] = target_data
    
    with open(output, 'w') as f:
        json.dump(data, f, indent=2)
    
    console.print(f"[green]‚úì Exported to {output}[/]") if console else print(f"Exported to {output}")
    return 0

def cmd_install(args):
    """Install tools"""
    if os.geteuid() != 0:
        console.print("[red]‚úó Please run with sudo[/]") if console else print("Run with sudo")
        return 1
    
    console.print("[cyan]Installing reconnaissance tools...[/]") if console else print("Installing...")
    
    # Go tools (ProjectDiscovery + community)
    go_tools = [
        # Subdomain enumeration
        "github.com/projectdiscovery/subfinder/v2/cmd/subfinder@latest",
        "github.com/tomnomnom/assetfinder@latest",
        "github.com/gwen001/github-subdomains@latest",
        # DNS
        "github.com/projectdiscovery/dnsx/cmd/dnsx@latest",
        "github.com/projectdiscovery/shuffledns/cmd/shuffledns@latest",
        "github.com/d3mondev/puredns/v2@latest",
        "github.com/hakluke/hakrevdns@latest",
        # ASN/IP
        "github.com/projectdiscovery/asnmap/cmd/asnmap@latest",
        "github.com/projectdiscovery/mapcidr/cmd/mapcidr@latest",
        # Ports
        "github.com/projectdiscovery/naabu/v2/cmd/naabu@latest",
        # HTTP
        "github.com/projectdiscovery/httpx/cmd/httpx@latest",
        "github.com/tomnomnom/httprobe@latest",
        # URLs
        "github.com/lc/gau/v2/cmd/gau@latest",
        "github.com/tomnomnom/waybackurls@latest",
        "github.com/projectdiscovery/katana/cmd/katana@latest",
        "github.com/hakluke/hakrawler@latest",
        "github.com/jaeles-project/gospider@latest",
        # JS
        "github.com/003random/getJS@latest",
        "github.com/lc/subjs@latest",
        # Content
        "github.com/ffuf/ffuf/v2@latest",
        # Takeover
        "github.com/haccer/subjack@latest",
        # Screenshots
        "github.com/sensepost/gowitness@latest",
        # Nuclei (for takeover templates)
        "github.com/projectdiscovery/nuclei/v3/cmd/nuclei@latest",
    ]
    
    # Python tools
    pip_tools = [
        "dnsgen",
        "altdns",
        "arjun",
        "paramspider",
        "linkfinder",
        "s3scanner",
    ]
    
    # APT packages (Debian/Ubuntu/Kali)
    apt_tools = [
        "amass",
        "findomain",
        "massdns",
        "nmap",
        "masscan",
        "whatweb",
        "feroxbuster",
        "theharvester",
        "eyewitness",
        "dnsrecon",
        "jq",
        "proxychains4",
    ]
    
    os.environ["GOPATH"] = str(Path.home() / "go")
    os.environ["PATH"] = os.environ["PATH"] + ":" + str(Path.home() / "go" / "bin")
    
    # Install Go tools
    console.print("\n[bold cyan]Installing Go tools...[/]") if console else None
    for tool in go_tools:
        name = tool.split('/')[-1].split('@')[0]
        console.print(f"  [dim]go install[/] {name}") if console else print(f"Installing {name}")
        result = subprocess.run(["go", "install", tool], capture_output=True, text=True)
        if result.returncode != 0:
            console.print(f"    [yellow]‚ö† Failed[/]") if console else None
    
    # Copy Go binaries to /usr/local/bin
    go_bin = Path.home() / "go" / "bin"
    if go_bin.exists():
        for f in go_bin.iterdir():
            try:
                shutil.copy(str(f), "/usr/local/bin/")
            except Exception:
                pass
    
    # Install Python tools
    console.print("\n[bold cyan]Installing Python tools...[/]") if console else None
    for tool in pip_tools:
        console.print(f"  [dim]pip install[/] {tool}") if console else print(f"Installing {tool}")
        subprocess.run(["pip3", "install", tool], capture_output=True)
    
    # Install APT packages
    console.print("\n[bold cyan]Installing system packages...[/]") if console else None
    subprocess.run(["apt-get", "update", "-qq"], capture_output=True)
    for tool in apt_tools:
        console.print(f"  [dim]apt install[/] {tool}") if console else print(f"Installing {tool}")
        subprocess.run(["apt-get", "install", "-y", "-qq", tool], capture_output=True)
    
    # Install additional tools that need special handling
    console.print("\n[bold cyan]Installing additional tools...[/]") if console else None
    
    # Kiterunner
    console.print("  [dim]Installing[/] kiterunner") if console else None
    subprocess.run([
        "bash", "-c",
        "cd /tmp && git clone https://github.com/assetnote/kiterunner.git 2>/dev/null && cd kiterunner && make build && cp dist/kr /usr/local/bin/ 2>/dev/null"
    ], capture_output=True)
    
    # x8 (Rust)
    console.print("  [dim]Installing[/] x8") if console else None
    subprocess.run(["cargo", "install", "x8"], capture_output=True)
    
    # favfreak
    console.print("  [dim]Installing[/] favfreak") if console else None
    subprocess.run([
        "bash", "-c",
        "pip3 install mmh3 && cd /tmp && git clone https://github.com/devanshbatham/FavFreak.git 2>/dev/null && cp FavFreak/favfreak.py /usr/local/bin/favfreak && chmod +x /usr/local/bin/favfreak 2>/dev/null"
    ], capture_output=True)
    
    # webanalyze
    console.print("  [dim]Installing[/] webanalyze") if console else None
    subprocess.run(["go", "install", "github.com/rverton/webanalyze/cmd/webanalyze@latest"], capture_output=True)
    
    # cloud_enum
    console.print("  [dim]Installing[/] cloud_enum") if console else None
    subprocess.run([
        "bash", "-c",
        "cd /tmp && git clone https://github.com/initstring/cloud_enum.git 2>/dev/null && cd cloud_enum && pip3 install -r requirements.txt && ln -sf $(pwd)/cloud_enum.py /usr/local/bin/cloud_enum 2>/dev/null"
    ], capture_output=True)
    
    # emailfinder
    console.print("  [dim]Installing[/] emailfinder") if console else None
    subprocess.run(["pip3", "install", "emailfinder"], capture_output=True)
    
    # Update nuclei templates
    console.print("\n[bold cyan]Updating nuclei templates...[/]") if console else None
    subprocess.run(["nuclei", "-update-templates"], capture_output=True)
    
    # Create resolvers file if missing
    resolvers_file = Path.home() / ".macaron" / "config" / "resolvers.txt"
    if not resolvers_file.exists():
        console.print("\n[bold cyan]Creating resolvers file...[/]") if console else None
        resolvers_file.parent.mkdir(parents=True, exist_ok=True)
        resolvers = [
            "8.8.8.8", "8.8.4.4", "1.1.1.1", "1.0.0.1",
            "9.9.9.9", "149.112.112.112", "208.67.222.222", "208.67.220.220"
        ]
        with open(resolvers_file, 'w') as f:
            f.write('\n'.join(resolvers))
    
    console.print("\n[green]‚úì Installation complete![/]") if console else print("Done!")
    console.print("[dim]Run 'macaron -L' to check installed tools[/]") if console else None
    return 0

def cmd_update(args):
    """Self-update macaron from GitHub"""
    if console:
        console.print("[cyan]Checking for updates...[/]")
    
    repo_url = "https://github.com/root-Manas/macaron"
    raw_url = "https://raw.githubusercontent.com/root-Manas/macaron/main/macaron"
    
    try:
        import urllib.request
        
        # Fetch latest version from GitHub
        version_check_url = "https://raw.githubusercontent.com/root-Manas/macaron/main/macaron"
        with urllib.request.urlopen(version_check_url, timeout=15) as response:
            remote_content = response.read().decode('utf-8')
        
        # Extract version from remote
        remote_version = None
        for line in remote_content.split('\n'):
            if line.strip().startswith('VERSION = "'):
                remote_version = line.split('"')[1]
                break
        
        if not remote_version:
            console.print("[red]‚úó Could not determine remote version[/]") if console else print("Version check failed")
            return 1
        
        if console:
            console.print(f"  Current version: [cyan]{VERSION}[/]")
            console.print(f"  Latest version:  [cyan]{remote_version}[/]")
        
        # Compare versions
        if remote_version == VERSION:
            console.print("[green]‚úì Already up to date![/]") if console else print("Already up to date")
            return 0
        
        if console:
            console.print(f"\n[yellow]Update available: {VERSION} ‚Üí {remote_version}[/]")
        
        # Find current script location
        current_script = Path(__file__).resolve()
        
        # Check if we can write to the location
        if not os.access(current_script.parent, os.W_OK):
            if console:
                console.print("[yellow]‚ö† Need elevated permissions to update[/]")
                console.print(f"\n[dim]Run with sudo:[/]")
                console.print(f"  sudo macaron -U")
                console.print(f"\n[dim]Or manually update:[/]")
                console.print(f"  curl -sL {raw_url} -o {current_script}")
            return 1
        
        # Download and update
        if console:
            console.print("[cyan]Downloading update...[/]")
        
        # Backup current version
        backup_path = current_script.with_suffix('.bak')
        shutil.copy(current_script, backup_path)
        
        try:
            # Write new version
            with open(current_script, 'w', encoding='utf-8') as f:
                f.write(remote_content)
            
            # Make executable
            os.chmod(current_script, 0o755)
            
            # Clean up backup
            backup_path.unlink()
            
            if console:
                console.print(f"[green]‚úì Updated to {remote_version}![/]")
                console.print(f"[dim]Restart macaron to use the new version[/]")
            else:
                print(f"Updated to {remote_version}")
            
            return 0
            
        except Exception as e:
            # Restore backup on failure
            if backup_path.exists():
                shutil.copy(backup_path, current_script)
                backup_path.unlink()
            raise e
            
    except urllib.error.URLError as e:
        console.print(f"[red]‚úó Network error: {e.reason}[/]") if console else print(f"Network error: {e}")
        return 1
    except Exception as e:
        console.print(f"[red]‚úó Update failed: {e}[/]") if console else print(f"Update failed: {e}")
        if console:
            console.print(f"\n[dim]Manual update:[/]")
            console.print(f"  git clone {repo_url}")
            console.print(f"  cd macaron && sudo cp macaron /usr/local/bin/")
        return 1

# ============== MAIN ==============

def main():
    parser = argparse.ArgumentParser(
        prog="macaron",
        description="Macaron v2.3 - Security Reconnaissance Platform",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  macaron -s example.com              Wide scan (default)
  macaron -s app.com -n               Narrow scan (app-focused)
  macaron -s target.com -f            Fast scan (quick wins)
  macaron -s target.com -m deep       Deep comprehensive scan
  macaron -s target.com -m osint      OSINT reconnaissance
  macaron -s target.com --slow        Slow mode (10 req/s)
  macaron -S                          Show status
  macaron -L                          List tools
  macaron -R -d example.com           Show results
  macaron -G -d example.com           Generate screenshot gallery
  macaron -U                          Update macaron to latest
  macaron -P                          Show pipeline config path

Scan Modes:
  wide   - Full infrastructure reconnaissance (default)
  narrow - Application-focused testing
  fast   - Quick reconnaissance
  osint  - OSINT and passive reconnaissance
  deep   - Comprehensive deep scan

Pipeline Configuration:
  Edit ~/.macaron/config/pipeline.yaml to customize:
  - Tool commands and options
  - Scan stages and order
  - Rate limits and timeouts
  - Create custom scan modes
        """
    )
    
    # Main actions (short flags)
    parser.add_argument("-s", "--scan", dest="target", nargs="*", metavar="TARGET", help="Scan target(s)")
    parser.add_argument("-S", "--status", action="store_true", help="Show status & summary")
    parser.add_argument("-R", "--results", action="store_true", help="Show results")
    parser.add_argument("-G", "--gallery", action="store_true", help="Generate screenshot gallery")
    parser.add_argument("-L", "--list-tools", action="store_true", help="List installed tools")
    parser.add_argument("-U", "--update", action="store_true", help="Update macaron to latest version")
    parser.add_argument("-E", "--export", action="store_true", help="Export results")
    parser.add_argument("-I", "--install", action="store_true", help="Install recon tools (sudo)")
    parser.add_argument("-C", "--config", action="store_true", help="Show config")
    parser.add_argument("-P", "--pipeline", action="store_true", help="Show pipeline.yaml path")
    
    # Scan options
    parser.add_argument("-m", "--mode", metavar="MODE", help="Scan mode (wide/narrow/fast/osint/deep)")
    parser.add_argument("-f", "--fast", action="store_true", help="Fast mode (minimal tools)")
    parser.add_argument("-n", "--narrow", action="store_true", help="Narrow mode (app-focused)")
    parser.add_argument("-F", "--file", metavar="FILE", help="Targets from file")
    parser.add_argument("--stdin", action="store_true", help="Read from stdin")
    parser.add_argument("--no-proxy", action="store_true", help="Disable proxychains")
    parser.add_argument("--slow", action="store_true", help="Slow mode (10 req/s)")
    parser.add_argument("--rate", type=int, help="Rate limit (req/s)")
    parser.add_argument("--threads", type=int, help="Threads")
    parser.add_argument("-q", "--quiet", action="store_true", help="Quiet mode")
    parser.add_argument("--resume", action="store_true", help="Resume interrupted scan")
    
    # Results options
    parser.add_argument("-d", "--domain", help="Filter by domain")
    parser.add_argument("-w", "--what", choices=["all", "subdomains", "live", "ports", "urls", "js", "vulns", "diff"], help="What to show")
    parser.add_argument("--limit", type=int, default=50, help="Limit results")
    
    # Config options
    parser.add_argument("--webhook", metavar="URL", help="Set Discord webhook")
    parser.add_argument("--test", action="store_true", help="Test webhook")
    parser.add_argument("--show", action="store_true", help="Show config")
    
    # Export options
    parser.add_argument("-o", "--output", help="Output file")
    
    # Meta
    parser.add_argument("-v", "--verbose", action="store_true", help="Verbose")
    parser.add_argument("--version", action="version", version=f"macaron {VERSION}")
    
    args = parser.parse_args()
    
    # Route to appropriate command
    if args.target is not None or args.file or args.stdin:
        return cmd_scan(args)
    elif args.status:
        return cmd_status(args)
    elif args.results:
        return cmd_show(args)
    elif args.gallery:
        return cmd_gallery(args)
    elif args.list_tools:
        return cmd_tools(args)
    elif args.update:
        return cmd_update(args)
    elif args.pipeline:
        # Show pipeline config path
        ensure_dir(CONFIG_DIR)
        if not PIPELINE_FILE.exists() and BUNDLED_PIPELINE.exists():
            shutil.copy(BUNDLED_PIPELINE, PIPELINE_FILE)
        if console:
            console.print(f"\n[bold cyan]Pipeline Config:[/] {PIPELINE_FILE}")
            console.print(f"\n[dim]Edit this file to customize tool commands, stages, and modes.[/]")
            if PIPELINE_FILE.exists():
                console.print(f"\n[green]‚úì Config exists[/]")
            else:
                console.print(f"\n[yellow]! Config will be created on first scan[/]")
        else:
            print(f"Pipeline config: {PIPELINE_FILE}")
        return 0
    elif args.export:
        return cmd_export(args)
    elif args.install:
        return cmd_install(args)
    elif args.config or args.webhook:
        return cmd_config(args)
    else:
        # Show help with banner
        if console:
            console.print(BANNER.format(version=VERSION))
        parser.print_help()
        return 0

if __name__ == "__main__":
    sys.exit(main())
